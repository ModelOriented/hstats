% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/PDP.R
\name{PDP}
\alias{PDP}
\alias{PDP.default}
\alias{PDP.ranger}
\alias{PDP.Learner}
\title{Partial Dependence Plot}
\usage{
PDP(object, ...)

\method{PDP}{default}(
  object,
  v,
  X,
  pred_fun = stats::predict,
  BY = NULL,
  by_size = 5L,
  grid = NULL,
  grid_size = 49L,
  trim = c(0.01, 0.99),
  strategy = c("uniform", "quantile"),
  n_max = 1000L,
  w = NULL,
  plot = (length(v) + !is.null(BY)) <= 2L,
  rotate_x = FALSE,
  color = "#2b51a1",
  facet_scales = "free_y",
  ...
)

\method{PDP}{ranger}(
  object,
  v,
  X,
  pred_fun = function(m, X, ...) stats::predict(m, X, ...)$predictions,
  BY = NULL,
  by_size = 5L,
  grid = NULL,
  grid_size = 49L,
  trim = c(0.01, 0.99),
  strategy = c("uniform", "quantile"),
  n_max = 1000L,
  w = NULL,
  plot = (length(v) + !is.null(BY)) <= 2L,
  rotate_x = FALSE,
  color = "#2b51a1",
  facet_scales = "free_y",
  ...
)

\method{PDP}{Learner}(
  object,
  v,
  X,
  pred_fun = function(m, X) m$predict_newdata(X)$response,
  BY = NULL,
  by_size = 5L,
  grid = NULL,
  grid_size = 49L,
  trim = c(0.01, 0.99),
  strategy = c("uniform", "quantile"),
  n_max = 1000L,
  w = NULL,
  plot = (length(v) + !is.null(BY)) <= 2L,
  rotate_x = FALSE,
  color = "#2b51a1",
  facet_scales = "free_y",
  ...
)
}
\arguments{
\item{object}{Fitted model object.}

\item{...}{Additional arguments passed to \code{pred_fun(object, X, ...)},
for instance \code{type = "response"} in a \code{\link[=glm]{glm()}} model.}

\item{v}{Vector of feature names.}

\item{X}{A data.frame or matrix serving as background dataset.}

\item{pred_fun}{Prediction function of the form \verb{function(object, X, ...)},
providing K >= 1 numeric predictions per row. Its first argument represents the
model \code{object}, its second argument a data structure like \code{X}. Additional arguments
(such as \code{type = "response"} in a GLM) can be passed via \code{...}. The default,
\code{\link[stats:predict]{stats::predict()}}, will work in most cases. Note that column names in a resulting
matrix of predictions will be used as default column names in the results.}

\item{BY}{Optional grouping vector or a column name. The partial dependence
function is calculated per \code{BY} group. Each \code{BY} group
uses the same evaluation grid to improve assessment of (non-)additivity.
Numeric \code{BY} variables with more than \code{by_size} disjoint values will be
binned into \code{by_size} quantile groups of similar size. Subsampling of \code{X} is done
within group.}

\item{by_size}{Numeric \code{BY} variables with more than \code{by_size} unique values will
be binned into quantile groups. Only relevant if \code{BY} is not \code{NULL}.}

\item{grid}{A vector (if \code{length(v) == 1L}), or a matrix/data.frame otherwise.
If \code{NULL}, calculated via \code{\link[=multivariate_grid]{multivariate_grid()}}.}

\item{grid_size}{Controls the approximate grid size. If \code{x} has p columns, then each
(non-discrete) column will be reduced to about the p-th root of \code{grid_size} values.}

\item{trim}{A non-discrete numeric variable is trimmed at these quantile
probabilities before calculations. Set to \code{c(0, 1)} for no trimming.}

\item{strategy}{How to find evaluation points of non-discrete numeric columns?
Either "uniform" (via \code{\link[=pretty]{pretty()}}) or "quantile", see description of
\code{\link[=univariate_grid]{univariate_grid()}}.}

\item{n_max}{If \code{X} has more than \code{n_max} rows, a random sample of \code{n_max} rows is
selected from \code{X}. In this case, set a random seed for reproducibility.}

\item{w}{Optional vector of case weights for each row of \code{X}.}

\item{plot}{Should results be plotted? Default is \code{TRUE} in the univariable case and
in the bivariable case without \code{BY}.}

\item{rotate_x}{Should x axis labels be rotated by 45 degrees?
(Only if \code{plot = TRUE}.)}

\item{color}{Color of lines and points of univariable PDP (without \code{BY}).}

\item{facet_scales}{Value passed to \code{facet_wrap(scales = ...)}, only relevant
for multivariate output and if \code{plot = TRUE}.}
}
\value{
If \code{plot = TRUE}, a "ggplot" object. Otherwise a data.frame with the evaluation
grid, the optional \code{BY} variable, and the corresponding partial dependencies as
columns.
}
\description{
Estimates the partial dependence function of feature(s) \code{v} over a
grid of values. Both multivariate and multivariable situations are supported.
By default, the resulting values are plotted.
}
\section{Methods (by class)}{
\itemize{
\item \code{PDP(default)}: Default method.

\item \code{PDP(ranger)}: Method for "ranger" models.

\item \code{PDP(Learner)}: Method for "mlr3" models.

}}
\section{Partial Dependence Functions}{


Let \eqn{F: R^p \to R} denote the prediction function that maps the
\eqn{p}-dimensional feature vector \eqn{\mathbf{x} = (x_1, \dots, x_p)}
to its prediction. Furthermore, let
\deqn{
  F_s(\mathbf{x}_s) = E_{\mathbf{x}_{\setminus s}}(F(\mathbf{x}_s, \mathbf{x}_{\setminus s}))
}
be the partial dependence function of \eqn{F} on the feature subset
\eqn{\mathbf{x}_s}, where \eqn{s \subseteq \{1, \dots, p\}}, as introduced in
Friedman (2001). Here, the expectation runs over the joint marginal distribution
of features \eqn{\mathbf{x}_{\setminus s}} not in \eqn{\mathbf{x}_s}.

Given data, \eqn{F_s(\mathbf{x}_s)} can be estimated by the empirical partial
dependence function

\deqn{
  \hat F_s(\mathbf{x}_s) = \frac{1}{n} \sum_{i = 1}^n F(\mathbf{x}_s, \mathbf{x}_{i\setminus s}),
}
where \eqn{\mathbf{x}_{i\setminus s}} \eqn{i = 1, \dots, n}, are the observed values
of \eqn{\mathbf{x}_{\setminus s}}.

A partial dependence plot (PDP) plots the values of \eqn{\hat F_s(\mathbf{x}_s)}
over a grid of evaluation points \eqn{\mathbf{x}_s}.
}

\examples{
# MODEL 1: Linear regression
fit <- lm(Sepal.Length ~ . + Species * Petal.Length, data = iris)
PDP(fit, v = "Species", X = iris)
PDP(fit, v = "Species", X = iris, plot = FALSE)

# Stratified by numeric BY variable (which is automatically binned)
PDP(fit, v = "Species", X = iris, BY = "Petal.Length")

# Multivariable input
PDP(fit, v = c("Species", "Petal.Width"), X = iris, grid_size = 100L)

# MODEL 2: Multi-response linear regression
fit <- lm(as.matrix(iris[1:2]) ~ Petal.Length + Petal.Width * Species, data = iris)
PDP(fit, v = "Petal.Width", X = iris, BY = iris$Species)
PDP(fit, v = c("Species", "Petal.Width"), X = iris, rotate_x = TRUE)

# Multivariate, multivariable, and BY (no plot)
PDP(fit, v = c("Petal.Width", "Petal.Length"), X = iris, BY = "Species")

# MODEL 3: Gamma GLM -> pass options to predict() via ...
fit <- glm(
  Sepal.Length ~ . + Petal.Width:Species, 
  data = iris, 
  family = Gamma(link = log)
)
PDP(fit, v = "Species", X = iris, type = "response")
}
\references{
Friedman, Jerome H. \emph{"Greedy Function Approximation: A Gradient Boosting Machine."}
Annals of Statistics 29, no. 5 (2001): 1189-1232.
}

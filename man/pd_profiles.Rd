% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/pd_profiles.R
\name{pd_profiles}
\alias{pd_profiles}
\alias{pd_profiles.default}
\alias{pd_profiles.ranger}
\alias{pd_profiles.Learner}
\title{Fast Partial Dependence Function}
\usage{
pd_profiles(object, ...)

\method{pd_profiles}{default}(
  object,
  v,
  X,
  pred_fun = stats::predict,
  grid = NULL,
  grid_size = 36L,
  trim = c(0.01, 0.99),
  strategy = c("quantile", "uniform"),
  n_max = 1000L,
  w = NULL,
  verbose = TRUE,
  ...
)

\method{pd_profiles}{ranger}(
  object,
  v,
  X,
  pred_fun = function(m, X, ...) stats::predict(m, X, ...)$predictions,
  grid = NULL,
  grid_size = 36L,
  trim = c(0.01, 0.99),
  strategy = c("quantile", "uniform"),
  n_max = 1000L,
  w = NULL,
  verbose = TRUE,
  ...
)

\method{pd_profiles}{Learner}(
  object,
  v,
  X,
  pred_fun = function(m, X) m$predict_newdata(X)$response,
  grid = NULL,
  grid_size = 36L,
  trim = c(0.01, 0.99),
  strategy = c("quantile", "uniform"),
  n_max = 1000L,
  w = NULL,
  verbose = TRUE,
  ...
)
}
\arguments{
\item{object}{Fitted model object.}

\item{...}{Additional arguments passed to \code{pred_fun(object, X, ...)}.}

\item{v}{Vector of feature names.}

\item{X}{A data.frame or matrix serving as background dataset.}

\item{pred_fun}{Prediction function of the form \verb{function(object, X, ...)},
providing K >= 1 numeric predictions per row. Its first argument represents the
model \code{object}, its second argument a data structure like \code{X}. Additional arguments
(such as \code{type = "response"} in a GLM) can be passed via \code{...}. The default,
\code{\link[stats:predict]{stats::predict()}}, will work in most cases. Note that column names in a resulting
matrix of predictions will be used as default column names in the results.}

\item{grid}{Named list. Each element specifies the evaluation grid for the
corresponding feature. Missing components are automatically added. If \code{v} has
length 1, then \code{grid} can also be a vector.}

\item{grid_size}{Controls the approximate grid size. If \code{X} has p columns, then each
(non-discrete) column will be reduced to about the p-th root of \code{grid_size} values.}

\item{trim}{Non-discrete columns are trimmed at corresponding quantiles.
Set to \code{c(0, 1)} for no trimming.}

\item{strategy}{How should evaluation points of non-discrete columns be found?
Either "quantile" or "uniform".}

\item{n_max}{If \code{X} has more than \code{n_max} rows, a random sample of \code{n_max} rows is
selected for calculations (after determining \code{grid}).}

\item{w}{Optional vector of case weights for each row of \code{X}.}

\item{verbose}{Should a progress bar be shown? The default is \code{TRUE}.}
}
\value{
An object of class "pd_profiles", containing these elements:
\itemize{
\item \code{grid}: Named list of evaluation points.
\item \code{pd}: Named list of PD matrices.
\item \code{v}: Same as input \code{v}.
}
}
\description{
Fast implementation of Friedman's (empirical) partial dependence (PD) function
of feature subset \eqn{J}, given by
\deqn{\textrm{PD}_J(v) = \frac{1}{|D|} \sum_{i \in D} \hat f(v, x_{i,\setminus J})},
where
\itemize{
\item \eqn{D} is a reference data set,
\item \eqn{J} is a index set
\item \eqn{\hat f} is the fitted model, and
\item \eqn{x_{i,\setminus J}} is the feature vector of the i-th observation without
components in \eqn{J} (which are replaced by the function argument(s) \eqn{v}).
}

The function supports both
\itemize{
\item multivariate predictions (e.g., multi-classification settings) and
\item multivariate grids.
}
}
\section{Methods (by class)}{
\itemize{
\item \code{pd_profiles(default)}: Default method.

\item \code{pd_profiles(ranger)}: Method for "ranger" models.

\item \code{pd_profiles(Learner)}: Method for "mlr3" models.

}}
\examples{
# MODEL ONE: Linear regression
fit <- lm(Sepal.Length ~ ., data = iris)
pd <- pd_profiles(fit, v = names(iris[-1]), X = iris)
pd
head(summary(pd))
summary(pd, "Species")

pd <- pd_profiles(fit, v = "Petal.Width", X = iris, grid = seq(0, 1, by = 0.5))
summary(pd)
summary(pd_profiles(fit, v = "Petal.Width", X = iris, grid = seq(1, 0, by = -0.5)))
summary(pd_profiles(fit, v = "Species", X = iris))

# MODEL TWO: Multi-response linear regression
fit <- lm(as.matrix(iris[1:2]) ~ Petal.Length + Petal.Width + Species, data = iris)
v <- names(iris[3:5])
partial_grid <- list(Petal.Width = seq(0, 1, by = 0.5))
pd <- pd_profiles(fit, v = v, X = iris, grid = partial_grid, verbose = FALSE)
summary(pd, "Species")
summary(pd, "Petal.Width")
head(summary(pd, "Petal.Length"))

# MODEL THREE: Gamma GLM with log link
fit <- glm(
  Sepal.Length ~ . + Petal.Width:Species, 
  data = iris, 
  family = Gamma(link = log)
)
summary(pd_profiles(fit, v = "Species", X = iris, type = "response"))
}
\references{
Friedman J. H. (2001). Greedy function approximation: A gradient boosting machine.
The Annals of Statistics, 29:1189â€“1232.
}

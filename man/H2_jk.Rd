% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/H2_jk.R
\name{H2_jk}
\alias{H2_jk}
\alias{H2_jk.default}
\alias{H2_jk.ranger}
\alias{H2_jk.Learner}
\alias{H2_jk.interact}
\title{Pairwise Interaction Strength}
\usage{
H2_jk(object, ...)

\method{H2_jk}{default}(
  object,
  v,
  X,
  pred_fun = stats::predict,
  pairwise_m = 5L,
  n_max = 300L,
  w = NULL,
  verbose = TRUE,
  normalize = TRUE,
  denominator = c("F_jk", "F"),
  squared = TRUE,
  sort = TRUE,
  top_m = Inf,
  eps = 1e-08,
  ...
)

\method{H2_jk}{ranger}(
  object,
  v,
  X,
  pred_fun = function(m, X, ...) stats::predict(m, X, ...)$predictions,
  pairwise_m = 5L,
  n_max = 300L,
  w = NULL,
  verbose = TRUE,
  normalize = TRUE,
  denominator = c("F_jk", "F"),
  squared = TRUE,
  sort = TRUE,
  top_m = Inf,
  eps = 1e-08,
  ...
)

\method{H2_jk}{Learner}(
  object,
  v,
  X,
  pred_fun = function(m, X) m$predict_newdata(X)$response,
  pairwise_m = 5L,
  n_max = 300L,
  w = NULL,
  verbose = TRUE,
  normalize = TRUE,
  denominator = c("F_jk", "F"),
  squared = TRUE,
  sort = TRUE,
  top_m = Inf,
  eps = 1e-08,
  ...
)

\method{H2_jk}{interact}(
  object,
  normalize = TRUE,
  denominator = c("F_jk", "F"),
  squared = TRUE,
  sort = TRUE,
  top_m = Inf,
  eps = 1e-08,
  ...
)
}
\arguments{
\item{object}{Fitted model object.}

\item{...}{Additional arguments passed to \code{pred_fun(object, X, ...)}, for instance
\code{type = "response"} in a \code{\link[=glm]{glm()}} model.}

\item{v}{Vector of feature names.}

\item{X}{A data.frame or matrix serving as background dataset.}

\item{pred_fun}{Prediction function of the form \verb{function(object, X, ...)},
providing K >= 1 numeric predictions per row. Its first argument represents the
model \code{object}, its second argument a data structure like \code{X}. Additional arguments
(such as \code{type = "response"} in a GLM) can be passed via \code{...}. The default,
\code{\link[stats:predict]{stats::predict()}}, will work in most cases. Note that column names in a resulting
matrix of predictions will be used as default column names in the results.}

\item{pairwise_m}{Number of features for which pairwise statistics are calculated.
The features are selected based on Friedman and Popescu's overall interaction
strength \eqn{H^2_j} (rowwise maximum in the multivariate case).
Set to \code{length(v)} to not miss any pairwise interaction.
Set to 0 to not calculate any pairwise interaction.}

\item{n_max}{If \code{X} has more than \code{n_max} rows, a random sample of \code{n_max} rows is
selected from \code{X}. In this case, set a random seed for reproducibility.}

\item{w}{Optional vector of case weights for each row of \code{X}.}

\item{verbose}{Should a progress bar be shown? The default is \code{TRUE}.}

\item{normalize}{Should statistic be normalized? Default is \code{TRUE}.}

\item{denominator}{Should the denominator be the variation of the combined
effect \eqn{F_{jk}} (like Friedman and Popescu, default) or rather the
variation of the predictions. The latter has the advantage that values can
directly be compared across variable pairs (and are still relative).
Only relevant when \code{normalize = TRUE}.}

\item{squared}{Should \emph{squared} statistics be returned? Default is \code{TRUE}.}

\item{sort}{Should results be sorted by the size of the statistic? Default is \code{TRUE}.
Multioutput predictions are sorted by row means.}

\item{top_m}{How many statistics should be shown? By default \code{Inf} (show all).}

\item{eps}{Threshold below which numerator values are set to 0.}
}
\value{
Matrix of interactions statistics (one row per variable pair, one column per
prediction dimension).
}
\description{
Friedman and Popescu's statistics of pairwise interaction strength,
ideally calculated from the result of \code{\link[=interact]{interact()}}.
}
\details{
Following Friedman and Popescu (2008), if there are no interaction effects between
features \eqn{x_j} and \eqn{x_k}, their two-dimensional (centered) partial dependence
function \eqn{F_{jk}} can be written as the sum of the (centered) univariate partial
dependencies \eqn{F_j} and \eqn{F_k}, i.e.,
\deqn{
  F_{jk}(x_j, x_k) = F_j(x_j)+ F_k(x_k).
}
Correspondingly, Friedman and Popescu's \eqn{H_{jk}^2} statistic of pairwise interaction
strength is defined as
\deqn{
  H_{jk}^2 = \frac{A_{jk}}{B_{jk}},
}
where
\deqn{
   A_{jk} = \frac{1}{n} \sum_{i = 1}^n\big[\hat F_{jk}(x_{ij}, x_{ik}) - \hat F_j(x_{ij}) - \hat F_k(x_{ik})\big]^2
}
and
\deqn{
  B_{jk} = \frac{1}{n} \sum_{i = 1}^n\big[\hat F_{jk}(x_{ij}, x_{ik})\big]^2
}
(check \code{\link[=pd]{pd()}} for all definitions).
}
\section{Methods (by class)}{
\itemize{
\item \code{H2_jk(default)}: Default pairwise interaction strength.

\item \code{H2_jk(ranger)}: Pairwise interaction strength from "ranger" models.

\item \code{H2_jk(Learner)}: Pairwise interaction strength from "mlr3" models.

\item \code{H2_jk(interact)}: Pairwise interaction strength from "interact" object.

}}
\section{Remarks}{

\enumerate{
\item Remarks 1 to 4 of \code{\link[=H2_jk]{H2_jk()}} also apply here.
\item \eqn{H^2_{jk} = 0} means there are no interaction effects between \eqn{x_j}
and \eqn{x_k}. The larger the value, the more of the joint effect of the two
features comes from the interaction.
\item Since the denominator differs between variable pairs, unlike \eqn{H_j},
this test statistic is difficult to compare between variable pairs.
If both main effects are very weak, a negligible interaction can get a
high \eqn{H^2_{jk}}. Therefore, Friedman and Popescu (2008) suggests to calculate
\eqn{H^2_{jk}} only for \emph{important} variables.
}
}

\section{Alternatives}{


To be able to compare pairwise interaction strength across variable pairs,
and to overcome the problem mentioned in the last remark, we suggest as alternative
a different denominator, namely the same as used for \eqn{H^2_j}:
\deqn{
  \tilde H^2_{jk} = \frac{A_{jk}}{\frac{1}{n} \sum_{i = 1}^n\big[F(\mathbf{x}_i)\big]^2}.
}
This statistic would tell us how much of the total variance of the predictions comes
from the pairwise interaction of \eqn{x_j} and \eqn{x_k}. Use \code{denominator = "F"} to
apply this variant.

Another possibility would be to use the unnormalized test statistic on the scale
of the predictions, i.e., \eqn{\sqrt{A_{jk}}}. Set \code{normalize = FALSE} and
\code{squared = FALSE} to get this statistic.
}

\examples{
# MODEL ONE: Linear regression
fit <- lm(Sepal.Length ~ . + Petal.Width:Species, data = iris)
inter <- interact(fit, v = names(iris[-1]), X = iris, verbose = FALSE)
H2_jk(inter)                     # Proportion of pairwise effect variability
H2_jk(inter, denominator = "F")  # Proportion of prediction variability

\dontrun{
H2_jk(fit, v = names(iris[-1]), X = iris, verbose = FALSE)

# MODEL TWO: Multi-response linear regression
fit <- lm(as.matrix(iris[1:2]) ~ Petal.Length + Petal.Width * Species, data = iris)
v <- c("Petal.Length", "Petal.Width", "Species")
inter <- interact(fit, v = v, X = iris, verbose = FALSE)
H2_jk(inter)
H2_jk(fit, v = v, X = iris, verbose = FALSE)
}
}
\references{
Friedman, Jerome H., and Bogdan E. Popescu. \emph{"Predictive Learning via Rule Ensembles."}
The Annals of Applied Statistics 2, no. 3 (2008): 916-54.
}
